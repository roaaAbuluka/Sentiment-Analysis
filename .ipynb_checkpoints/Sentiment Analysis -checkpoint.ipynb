{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "from pandas import DataFrame\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file uploads as pandas data frame\n",
    "xls_file = pd.ExcelFile('//home//rua//Documents//Sentiment Analysis//Sentiment-Analysis//redata2.xlsx')\n",
    "print(xls_file.sheet_names)\n",
    "data = xls_file.parse('Sheet1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the data \n",
    "print(len(data))\n",
    "# remove null values \n",
    "data = data.dropna() \n",
    "# convert column \"label\" to int\n",
    "data['Label'] = data['Label'].astype(np.int)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop word removing function, stop words is the useless words in english such as a, an .\n",
    "def stopwordRemove(text):\n",
    "    ar_stopword_list = open(\"//home//rua//Documents//Sentiment Analysis//Sentiment-Analysis//stopwords_dictionary.xlsx\", \"r\")\n",
    "    stop_words = ar_stopword_list.read().split('\\n')\n",
    "    needed_words = []\n",
    "    words = word_tokenize(text)\n",
    "    for w in words:\n",
    "        if w not in (stop_words):\n",
    "            needed_words.append(w)\n",
    "    filtered_sentence = \" \".join(needed_words)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the stop word file\n",
    "ar_sw_file = open(\"//home//rua//Documents//Sentiment Analysis//Sentiment-Analysis//stopwords_dictionary.xlsx\")\n",
    "ar_list = ar_sw_file.read()\n",
    "print(stopwordRemove(\"دوما هي الافضل\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to reduce the words to the root word\n",
    "def steaming(text):\n",
    "    st = ISRIStemmer()\n",
    "    stemmed_words = []\n",
    "    words = word_tokenize(text)\n",
    "    for w in words:\n",
    "        stemmed_words.append(st.stem(w))\n",
    "    stemmed_sentence = ' '.join(stemmed_words)\n",
    "    return stemmed_sentence\n",
    "print(steaming(\"دوما هي الافضل\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize the text\n",
    "def normalizeArabic(text):\n",
    "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"و\", \"ؤ\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    return(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalizeArabic(\"دوما هي ألافضل\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove diacritics from words\n",
    "def deNoise(text):\n",
    "    noise = re.compile(\"\"\" ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(noise, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(deNoise(\"دوماٌ هي ألافضل\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove punctuations\n",
    "def strip_punctuation(text):\n",
    "    return ''.join(c for c in text if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove numbers\n",
    "def remove_numb(text):\n",
    "    return ''.join(c for c in text if not c.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove the stop-words, steaming \n",
    "def prepareDataSet(data):\n",
    "    sent = []\n",
    "    for index, r in data.iterrows():\n",
    "        text = stopwordRemove(r['text'])\n",
    "        text = steaming(r['text'])\n",
    "        text = normalizeArabic(r['text'])\n",
    "        text = deNoise(r['text'])\n",
    "        text = strip_punctuation(r['text'])\n",
    "        tetx = remove_numb(r['text'])\n",
    "        if r['Label'] == -1:\n",
    "            sent.append([text, 'neg'])\n",
    "        elif r['Label'] == 1:\n",
    "            sent.append([text, 'pos'])\n",
    "        elif r['Label'] == 0:\n",
    "            sent.append([text, 'obj'])\n",
    "    df_sent = DataFrame(sent, columns = ['text','Label'])\n",
    "    return df_sent\n",
    "prepareDataSet_data = prepareDataSet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(prepareDataSet_data)[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return term frequency–inverse document frequency witch is \n",
    "#a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
    "def FeatureExtraction(data):\n",
    "    vectorizer = TfidfVectorizer(min_df = 10, lowercase = False,max_df = 0.75, ngram_range = (1, 2))\n",
    "    tfidf_data = vectorizer.fit_transform(data)\n",
    "    return tfidf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learing(clf, X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = \\\n",
    "    cross_validation.train_test_split(X,Y, test_size = 0.4, random_state = 43)\n",
    "     \n",
    "    classifer = clf()\n",
    "    classifer.fit(X_train, Y_train)\n",
    "    predict = cross_validation.cross_val_predict(classifer, X_test, Y_test, cv=10)\n",
    "    score = cross_validation.cross_val_score(classifer, X_test, Y_test, cv=10)\n",
    "    print(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(clf):\n",
    "    xls_file = pd.ExcelFile('C:\\\\Users\\\\Roaa Abuluka\\\\Downloads\\\\redata2.xlsx')\n",
    "    data = xls_file.parse('Sheet1')\n",
    "    prepareDataSet_data = prepareDataSet(data)\n",
    "    data, target = prepareDataSet_data['text'], prepareDataSet_data['Label']\n",
    "    tfidf_data = FeatureExtraction(data)\n",
    "    learing(clf, tfidf_data, target)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [MultinomialNB, SVC, LogisticRegression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for clf in clfs:\n",
    "    main(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_file = pd.ExcelFile('C:\\\\Users\\\\Roaa Abuluka\\\\Downloads\\\\redata2.xlsx')\n",
    "data = xls_file.parse('Sheet1')\n",
    "prepareDataSet_data = prepareDataSet(data)\n",
    "data, target = prepareDataSet_data['text'], prepareDataSet_data['Label']\n",
    "tfidf_data = FeatureExtraction(data)\n",
    "learing(clf, tfidf_data, target)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search the hyper-parameter for KNN\n",
    "knn_clf = KNeighborsClassifier()\n",
    "param_knn = {\n",
    "    'n_neighbors': [1, 2]\n",
    "}\n",
    "knn_grid = GridSearchCV(knn_clf, param_knn, cv = 3, scoring = 'f1_micro', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "score = knn_grid.fit(tfidf_data, target)\n",
    "score.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score for KNN\n",
    "score.best_score_\n",
    "knn_clf = score.best_estimator_\n",
    "pred_y = knn_clf.predict(tfidf_data)\n",
    "accuracy_score(target, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix for KNN\n",
    "KNNconfusion = confusion_matrix(target, pred_y)\n",
    "knn_cm = KNNconfusion / KNNconfusion.astype(np.float).sum(axis=1)\n",
    "ax = plt.axes()\n",
    "df_cm = pd.DataFrame(knn_cm ,columns= [\"neg\", \"obj\", \"pos\"], index = [\"neg\", \"obj\", \"pos\"])\n",
    "sn.set(font_scale = 1.4)\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, cmap = \"Blues\" , ax = ax, xticklabels='auto')\n",
    "ax.set_title(\"Normalized Confusion Matrix\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search Naive Bayes hyper-parameter\n",
    "mltiNB_clf = MultinomialNB()\n",
    "param_MltiNB = {\n",
    "    'alpha': [0.0, 0.2, 0.5, 0.6, 0.8, 1.0]\n",
    "    \n",
    "}\n",
    "MultiNB_grid = GridSearchCV(mltiNB_clf, param_MltiNB, cv = 3, scoring = 'f1_micro', n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "MultiNB_score = MultiNB_grid.fit(tfidf_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiNB_score.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiNB_score.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score for NB\n",
    "bestMltiNB_clf = MultiNB_score.best_estimator_\n",
    "predNB_y = bestMltiNB_clf.predict(tfidf_data)\n",
    "accuracy_score(target,predNB_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix for Naive Bayes \n",
    "Naive_cm = confusion_matrix(target, predNB_y)\n",
    "NB_cm = Naive_cm / Naive_cm.astype(np.float).sum(axis=1)\n",
    "ax = plt.axes()\n",
    "df_cm = pd.DataFrame(NB_cm ,columns= [\"neg\", \"obj\", \"pos\"], index = [\"neg\", \"obj\", \"pos\"])\n",
    "sn.set(font_scale = 1.4)\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, cmap = \"gray_r\" , ax = ax, xticklabels='auto')\n",
    "ax.set_title(\"Normalized Confusion Matrix\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search SVM hyper-parameters\n",
    "param_svm = {\n",
    "    'kernel':('linear', 'rbf'),\n",
    "    'C':[5, 10, 15]\n",
    "}\n",
    "svm_grid = GridSearchCV(svc_clf, param_svm, cv=3, scoring = 'f1_micro', n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm_score = svm_grid.fit(tfidf_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_score.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_score.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score for SVM\n",
    "bestsvm_clf = svm_score.best_estimator_\n",
    "predSVM_y = bestsvm_clf.predict(tfidf_data)\n",
    "accuracy_score(target, predSVM_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix for support vector machine \n",
    "SVM_confustion = confusion_matrix(target, predSVM_y)\n",
    "SVM_cm = SVM_confustion / SVM_confustion.astype(np.float).sum(axis=1)\n",
    "ax = plt.axes()\n",
    "df_cm = pd.DataFrame(SVM_cm ,columns= [\"neg\", \"obj\", \"pos\"], index = [\"neg\", \"obj\", \"pos\"])\n",
    "sn.set(font_scale = 1.4)\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, cmap = \"Oranges\" , ax = ax, xticklabels='auto')\n",
    "ax.set_title(\"Normalized Confusion Matrix\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search logistic Regression hyper-parameters\n",
    "param_logistic = {\n",
    "    #'penalty':('12'),\n",
    "    'C':[0.2, 0.5, 0.6, 0.8, 1.0]\n",
    "}\n",
    "log_grid = GridSearchCV(log_clf, param_logistic, cv=3, scoring = 'f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log_score = log_grid.fit(tfidf_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score for Logistic Regression\n",
    "best_clf = log_score.best_estimator_\n",
    "predLOG_y = best_clf.predict(tfidf_data)\n",
    "accuracy_score(target, predLOG_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Logistic Regression confusion matrix  \n",
    "LR_confustion = confusion_matrix(target, predLOG_y)\n",
    "LR_cm = LR_confustion / LR_confustion.astype(np.float).sum(axis=1)\n",
    "ax = plt.axes()\n",
    "df_cm = pd.DataFrame(SVM_cm ,columns= [\"neg\", \"obj\", \"pos\"], index = [\"neg\", \"obj\", \"pos\"])\n",
    "sn.set(font_scale = 1.4)\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, cmap = \"Greens\" , ax = ax, xticklabels='auto')\n",
    "ax.set_title(\"Normalized Confusion Matrix\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
